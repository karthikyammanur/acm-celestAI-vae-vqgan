{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaheemJ/CelestAI/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am1-oQ_Uh4zk"
      },
      "outputs": [],
      "source": [
        "!pip install datasets pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbKy3_Dzh8Ct"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"MultimodalUniverse/legacysurvey\", split=\"train\", streaming=True)\n",
        "\n",
        "dataset_iter = iter(dataset)\n",
        "\n",
        "first_500 = [next(dataset_iter) for _ in range(500)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mllb-GaGh9dX"
      },
      "outputs": [],
      "source": [
        "print(first_500[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GNfvHQHi4jU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMG_SIZE = 64\n",
        "\n",
        "def preprocess_image(example):\n",
        "    \"\"\"Extract and process flux image data correctly.\"\"\"\n",
        "    flux_array = np.array(example[\"image\"][\"flux\"])\n",
        "    flux_array = np.mean(flux_array, axis=0)\n",
        "\n",
        "    #resize to (64, 64)\n",
        "    flux_resized = tf.image.resize(tf.convert_to_tensor(flux_array)[..., None], (IMG_SIZE, IMG_SIZE)).numpy()\n",
        "\n",
        "    #normalize to [0, 1]\n",
        "    flux_resized = (flux_resized - np.min(flux_resized)) / (np.max(flux_resized) - np.min(flux_resized))\n",
        "\n",
        "    return flux_resized\n",
        "\n",
        "#convert first 500 images\n",
        "train_images = np.array([preprocess_image(img) for img in first_500])\n",
        "\n",
        "print(f\"Dataset shape: {train_images.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_txSKUbViBb1"
      },
      "outputs": [],
      "source": [
        "plt.imshow(train_images[0], cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_ME5S9biFCa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixofAIvF9FhV"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"MultimodalUniverse/legacysurvey\", split=\"train\", streaming=True)\n",
        "\n",
        "dataset_iter = iter(dataset)\n",
        "\n",
        "first_500 = [next(dataset_iter) for _ in range(500)]\n",
        "\n",
        "IMG_SIZE = 64\n",
        "\n",
        "def preprocess_image(example):\n",
        "    \"\"\"Convert multimodal dataset format to a NumPy image array.\"\"\"\n",
        "    flux = np.array(example[\"image\"][\"flux\"])\n",
        "\n",
        "    image = flux[0]\n",
        "    image = np.clip(image, 0, 1)\n",
        "    image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "    image = image.resize((IMG_SIZE, IMG_SIZE))\n",
        "    image = np.array(image) / 255.0\n",
        "\n",
        "    return image\n",
        "\n",
        "#process images without saving locally\n",
        "train_images = np.array([preprocess_image(img) for img in first_500])\n",
        "\n",
        "#expand dimensions to match TensorFlow format\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "\n",
        "print(f\"Dataset shape: {train_images.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m2nyZNSjzP3"
      },
      "outputs": [],
      "source": [
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Reparameterization trick to sample from N(mu, var)\"\"\"\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3SYOEFDj1DG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Lambda, Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "LATENT_DIM = 16  #latent space dimension\n",
        "\n",
        "#encoder network\n",
        "def build_encoder():\n",
        "    input_img = Input(shape=(64, 64, 1))\n",
        "\n",
        "    x = Conv2D(32, (3,3), activation=\"relu\", strides=2, padding=\"same\")(input_img)\n",
        "    x = Conv2D(64, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    #latent space variables\n",
        "    z_mean = Dense(LATENT_DIM, name=\"z_mean\")(x)\n",
        "    z_log_var = Dense(LATENT_DIM, name=\"z_log_var\")(x)\n",
        "\n",
        "    #reparameterization \n",
        "    def sampling(args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], LATENT_DIM), mean=0., stddev=1.0)\n",
        "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    z = Lambda(sampling, output_shape=(LATENT_DIM,), name=\"z\")([z_mean, z_log_var])\n",
        "\n",
        "    encoder = Model(input_img, [z_mean, z_log_var, z], name=\"Encoder\")\n",
        "    return encoder\n",
        "\n",
        "encoder = build_encoder()\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcaT6pf0j2n5"
      },
      "outputs": [],
      "source": [
        "#decoder network\n",
        "def build_decoder():\n",
        "    latent_inputs = Input(shape=(LATENT_DIM,), name=\"z_sampling\")\n",
        "\n",
        "    x = Dense(16 * 16 * 64, activation=\"relu\")(latent_inputs)\n",
        "    x = Reshape((16, 16, 64))(x)\n",
        "    x = Conv2DTranspose(64, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    x = Conv2DTranspose(32, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    x = Conv2DTranspose(1, (3,3), activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "    decoder = Model(latent_inputs, x, name=\"Decoder\")\n",
        "    return decoder\n",
        "\n",
        "decoder = build_decoder()\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCLetnDZj4U4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed\n",
        "\n",
        "vae = VAE(encoder, decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE2Q6ieBn447"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMuG3FbWxscd"
      },
      "outputs": [],
      "source": [
        "def vae_loss(y_true, y_pred):\n",
        "    \"\"\"Custom VAE loss combining reconstruction loss and KL divergence.\"\"\"\n",
        "    reconstruction_loss = binary_crossentropy(K.flatten(y_true), K.flatten(y_pred))\n",
        "    reconstruction_loss *= 64 * 64\n",
        "\n",
        "    #KL divergence\n",
        "    z_mean, z_log_var, _ = encoder(y_true)\n",
        "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "\n",
        "    return K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "vae.compile(optimizer=\"adam\", loss=vae_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj_9nrNUxyaZ"
      },
      "outputs": [],
      "source": [
        "vae.fit(train_images, train_images, epochs=50, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf_x3XKG-D8X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_images(decoder, num_images=5):\n",
        "    random_latent_vectors = np.random.normal(size=(num_images, LATENT_DIM))\n",
        "    generated_images = decoder.predict(random_latent_vectors)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "    for i, img in enumerate(generated_images):\n",
        "        axes[i].imshow(img.squeeze(), cmap=\"gray\")\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "generate_images(decoder, num_images=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSsb8b_o-974"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "#compute reconstruction loss (MSE) between original and reconstructed images\n",
        "def compute_reconstruction_loss(vae, dataset, num_samples=100):\n",
        "    dataset_iter = iter(dataset)\n",
        "    losses = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        example = next(dataset_iter)\n",
        "        original_image = preprocess_image(example)  #convert to NumPy array\n",
        "        original_image = np.expand_dims(original_image, axis=0)  #add batch dim\n",
        "\n",
        "        reconstructed_image = vae(original_image)  #pass through VAE\n",
        "        loss = np.mean((original_image - reconstructed_image.numpy())**2)  #MSE\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "#test on first 100 images\n",
        "reconstruction_loss = compute_reconstruction_loss(vae, first_500[:500])\n",
        "print(f\"Average Reconstruction Loss: {reconstruction_loss}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
