{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaheemJ/CelestAI/blob/main/VQGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhHqSDRk9goa"
      },
      "outputs": [],
      "source": [
        "!pip install datasets pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEVJR4659poe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from datasets import load_dataset\n",
        "\n",
        "#hyperparameters (improved)\n",
        "IMG_SIZE        = 64\n",
        "BATCH_SIZE      = 32\n",
        "NUM_IMAGES      = 500\n",
        "LATENT_DIM      = 256\n",
        "NUM_EMBEDDINGS  = 1024\n",
        "COMMITMENT_COST = 0.5\n",
        "EPOCHS          = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0WTpA_u9rfP"
      },
      "outputs": [],
      "source": [
        "#load & buffer the first NUM_IMAGES from legacysurvey dataset\n",
        "ds_stream = load_dataset(\"MultimodalUniverse/legacysurvey\", split=\"train\", streaming=True)\n",
        "it = iter(ds_stream)\n",
        "raw = [next(it) for _ in range(NUM_IMAGES)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsE6PzXC9uZq"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = 64\n",
        "\n",
        "def preprocess(example):\n",
        "    flux = np.array(example[\"image\"][\"flux\"]) #shape (bands, H, W)\n",
        "    gray = np.mean(flux, axis=0) #average bands\n",
        "    gray = np.clip(gray, 0, 1)\n",
        "    img = Image.fromarray((gray * 255).astype(np.uint8))\n",
        "    img = img.resize((IMG_SIZE, IMG_SIZE))\n",
        "    arr = np.array(img, dtype=np.float32) / 255.0\n",
        "    return np.expand_dims(arr, -1)\n",
        "\n",
        "#build numpy array\n",
        "train_images = np.stack([preprocess(x) for x in raw], axis=0)\n",
        "print(\"Dataset shape:\", train_images.shape)\n",
        "\n",
        "#display a grid of images\n",
        "def display_image_grid(images, grid_size=5, title=\"Processed Images\"):\n",
        "    \"\"\"Display a grid of images from the dataset\"\"\"\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "\n",
        "    #display up to grid_size × grid_size images\n",
        "    num_images = min(grid_size * grid_size, len(images))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(grid_size, grid_size, i + 1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Image {i+1}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.9)\n",
        "    plt.show()\n",
        "\n",
        "#display a grid of 25 images\n",
        "display_image_grid(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roBASXBB9xli"
      },
      "outputs": [],
      "source": [
        "#create tf.data pipeline\n",
        "dataset = (\n",
        "    tf.data.Dataset\n",
        "      .from_tensor_slices(train_images)\n",
        "      .shuffle(1000)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyKb8R3z92U5"
      },
      "outputs": [],
      "source": [
        "#vector quantizer layer\n",
        "class VectorQuantizer(layers.Layer):\n",
        "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_embeddings  = num_embeddings\n",
        "        self.embedding_dim   = embedding_dim\n",
        "        self.commitment_cost = commitment_cost\n",
        "        # codebook: [D, K]\n",
        "        w_init = tf.random_uniform_initializer()\n",
        "        self.embeddings = tf.Variable(\n",
        "            initial_value=w_init(shape=(embedding_dim, num_embeddings)),\n",
        "            trainable=True, name=\"embeddings\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs: [B, H, W, D]\n",
        "        flat = tf.reshape(inputs, [-1, self.embedding_dim])  # [BHW, D]\n",
        "        # compute L2 distance to embeddings\n",
        "        distances = (\n",
        "            tf.reduce_sum(flat**2, axis=1, keepdims=True)\n",
        "            - 2 * tf.matmul(flat, self.embeddings)\n",
        "            + tf.reduce_sum(self.embeddings**2, axis=0, keepdims=True)\n",
        "        )  # [BHW, K]\n",
        "        indices = tf.argmin(distances, axis=1)               # [BHW]\n",
        "        one_hot = tf.one_hot(indices, self.num_embeddings)   # [BHW, K]\n",
        "        quantized = tf.matmul(one_hot, tf.transpose(self.embeddings))  # [BHW, D]\n",
        "        quantized = tf.reshape(quantized, tf.shape(inputs))            # [B,H,W,D]\n",
        "\n",
        "        # losses\n",
        "        e_latent_loss = tf.reduce_mean((tf.stop_gradient(quantized) - inputs)**2)\n",
        "        q_latent_loss = tf.reduce_mean((quantized - tf.stop_gradient(inputs))**2)\n",
        "        loss = q_latent_loss + self.commitment_cost * e_latent_loss\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # straight‑through estimator\n",
        "        return inputs + tf.stop_gradient(quantized - inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ui5TR6wv92Bs"
      },
      "outputs": [],
      "source": [
        "#encoder & decoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_encoder():\n",
        "    inp = keras.Input((IMG_SIZE, IMG_SIZE, 1))\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding=\"same\", activation=\"relu\")(inp)\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(LATENT_DIM, 1, padding=\"same\")(x)   # No activation on final bottleneck\n",
        "    return keras.Model(inputs=inp, outputs=x, name=\"encoder\")\n",
        "\n",
        "def build_decoder():\n",
        "    downscale = IMG_SIZE // 4  #two stride-2 convs reduce H/W by factor of 4\n",
        "    inp_shape = (downscale, downscale, LATENT_DIM)\n",
        "    inp = keras.Input(shape=inp_shape)\n",
        "    x = layers.Conv2DTranspose(256, 4, strides=2, padding=\"same\", activation=\"relu\")(inp)\n",
        "    x = layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.Conv2DTranspose(1,   3, strides=1, padding=\"same\", activation=\"sigmoid\")(x)\n",
        "    return keras.Model(inputs=inp, outputs=x, name=\"decoder\")\n",
        "\n",
        "#instantiate\n",
        "encoder = build_encoder()\n",
        "decoder = build_decoder()\n",
        "\n",
        "# Summaries (optional)\n",
        "encoder.summary()\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvVvHdQE91zp"
      },
      "outputs": [],
      "source": [
        "#discriminator\n",
        "def build_discriminator():\n",
        "    inp = keras.Input((IMG_SIZE,IMG_SIZE,1))\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding=\"same\", activation=\"leaky_relu\")(inp)\n",
        "    x = layers.Conv2D(128,4, strides=2, padding=\"same\", activation=\"leaky_relu\")(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1)(x)\n",
        "    return keras.Model(inp, x, name=\"discriminator\")\n",
        "\n",
        "discriminator = build_discriminator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8_UJmHp98MX"
      },
      "outputs": [],
      "source": [
        "#VQGAN custom Model\n",
        "class VQGAN(keras.Model):\n",
        "    def __init__(self, encoder, quantizer, decoder, discriminator, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.encoder       = encoder\n",
        "        self.quantizer     = quantizer\n",
        "        self.decoder       = decoder\n",
        "        self.discriminator = discriminator\n",
        "        self.l1_loss       = keras.losses.MeanAbsoluteError()\n",
        "        self.bce_loss      = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    def compile(self, g_optimizer, d_optimizer):\n",
        "        super().compile()\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_optimizer = d_optimizer\n",
        "\n",
        "    def train_step(self, real):\n",
        "        #generator (encoder - quantizer - decoder)\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            # encode - quantize - decode\n",
        "            z_e = self.encoder(real)\n",
        "            z_q = self.quantizer(z_e)\n",
        "            recon = self.decoder(z_q)\n",
        "\n",
        "            #recon loss with increased weight\n",
        "            recon_weight = 10.0  #higher weight on reconstruction quality\n",
        "            recon_loss = self.l1_loss(real, recon)\n",
        "\n",
        "            # adversarial loss for generator with decreased weight\n",
        "            adv_weight = 0.1  #lower weight on adversarial loss initially\n",
        "            fake_logits = self.discriminator(recon)\n",
        "            adv_loss_g = self.bce_loss(tf.ones_like(fake_logits), fake_logits)\n",
        "\n",
        "            g_loss = recon_weight * recon_loss + adv_weight * adv_loss_g + sum(self.quantizer.losses)\n",
        "\n",
        "            #discriminator loss remains the same\n",
        "            real_logits = self.discriminator(real)\n",
        "            adv_loss_d = (\n",
        "                self.bce_loss(tf.ones_like(real_logits), real_logits) +\n",
        "                self.bce_loss(tf.zeros_like(fake_logits), fake_logits)\n",
        "            )\n",
        "\n",
        "        #gradients\n",
        "        grads_g = gen_tape.gradient(g_loss, self.encoder.trainable_weights\n",
        "                                       + self.quantizer.trainable_weights\n",
        "                                       + self.decoder.trainable_weights)\n",
        "        grads_d = disc_tape.gradient(adv_loss_d, self.discriminator.trainable_weights)\n",
        "\n",
        "        #apply\n",
        "        self.g_optimizer.apply_gradients(zip(grads_g, self.encoder.trainable_weights\n",
        "                                                + self.quantizer.trainable_weights\n",
        "                                                + self.decoder.trainable_weights))\n",
        "        self.d_optimizer.apply_gradients(zip(grads_d, self.discriminator.trainable_weights))\n",
        "\n",
        "        return {\"g_loss\": g_loss, \"d_loss\": adv_loss_d, \"recon_loss\": recon_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5WvPi5o98I_"
      },
      "outputs": [],
      "source": [
        "#instantiate & compile VQGAN\n",
        "quantizer = VectorQuantizer(NUM_EMBEDDINGS, LATENT_DIM, COMMITMENT_COST)\n",
        "vqgan = VQGAN(encoder, quantizer, decoder, discriminator)\n",
        "\n",
        "vqgan.compile(\n",
        "    g_optimizer = keras.optimizers.Adam(1e-4),\n",
        "    d_optimizer = keras.optimizers.Adam(4e-4)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAxT5epj98GW"
      },
      "outputs": [],
      "source": [
        "#training loop with results printed every 10 epochs\n",
        "import tensorflow as tf\n",
        "\n",
        "#create a custom callback to print results every 10 epochs\n",
        "class PrintEveryNEpochs(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, n=5):\n",
        "        super(PrintEveryNEpochs, self).__init__()\n",
        "        self.n = n\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.n == 0:\n",
        "            print(f\"\\n=== Results after epoch {epoch + 1} ===\")\n",
        "            for metric_name, metric_value in logs.items():\n",
        "                print(f\"{metric_name}: {metric_value:.4f}\")\n",
        "            print(\"=\"*30)\n",
        "\n",
        "#create the callback\n",
        "print_callback = PrintEveryNEpochs(n=10)\n",
        "\n",
        "#add the callback to model.fit\n",
        "history = vqgan.fit(\n",
        "    dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[print_callback]\n",
        ")\n",
        "average_loss = compute_average_reconstruction_loss(vqgan, dataset)\n",
        "print(f\"\\nFinal Average Reconstruction Loss (L1): {average_loss:.6f}\")\n",
        "\n",
        "#to plot the training history after completion\n",
        "def plot_training_history(history):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    #plot all metrics except for per-layer losses\n",
        "    metrics_to_plot = [metric for metric in history.history.keys()\n",
        "                      if not metric.startswith('encoder_') and\n",
        "                         not metric.startswith('decoder_') and\n",
        "                         not metric.startswith('discriminator_')]\n",
        "\n",
        "    for metric in metrics_to_plot:\n",
        "        plt.plot(history.history[metric], label=metric)\n",
        "\n",
        "    plt.title('Training Metrics')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def generate_improved(n=5, temperature=0.8):\n",
        "    \"\"\"Generate images with temperature control for smoother results\"\"\"\n",
        "    \n",
        "\n",
        "    #get a batch of real images from the dataset\n",
        "    for batch in dataset.take(1):\n",
        "        real_images = batch\n",
        "\n",
        "    #encode and quantize\n",
        "    z_e = encoder(real_images)\n",
        "    z_q = quantizer(z_e)\n",
        "\n",
        "    #create variations by adding controlled noise\n",
        "    noise = tf.random.normal(shape=z_q.shape, stddev=temperature)\n",
        "    z_variations = z_q + noise\n",
        "\n",
        "    #generate n new samples with the modified latents\n",
        "    selected = z_variations[:n]\n",
        "    samples = decoder(selected)\n",
        "\n",
        "    return samples.numpy()\n",
        "\n",
        "def denoise_images(images, strength=0.7):\n",
        "    \"\"\"Apply simple denoising to the generated images\"\"\"\n",
        "    from scipy.ndimage import gaussian_filter\n",
        "\n",
        "    processed = []\n",
        "    for img in images:\n",
        "        #apply Gaussian blur for denoising\n",
        "        denoised = gaussian_filter(img.squeeze(), sigma=strength)\n",
        "        #normalize back to [0,1] range\n",
        "        denoised = (denoised - denoised.min()) / (denoised.max() - denoised.min())\n",
        "        #add channel dimension back if needed\n",
        "        if len(denoised.shape) == 2:\n",
        "            denoised = np.expand_dims(denoised, -1)\n",
        "        processed.append(denoised)\n",
        "\n",
        "    return np.array(processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCgFwU_D-FrJ"
      },
      "outputs": [],
      "source": [
        "#generate new samples\n",
        "def generate(n=5):\n",
        "    #print dimensions of quantizer embeddings to verify\n",
        "    print(f\"Quantizer embeddings shape: {quantizer.embeddings.shape}\")\n",
        "\n",
        "    #sample random indices\n",
        "    idx = tf.random.uniform((n, IMG_SIZE//4, IMG_SIZE//4), maxval=NUM_EMBEDDINGS, dtype=tf.int32)\n",
        "    one_hot = tf.one_hot(idx, NUM_EMBEDDINGS)  # [n, h, w, K]\n",
        "    print(f\"One-hot shape: {one_hot.shape}\")\n",
        "\n",
        "    \n",
        "    flat_one_hot = tf.reshape(one_hot, [-1, NUM_EMBEDDINGS])  # [n*h*w, K]\n",
        "    flat_quantized = tf.matmul(flat_one_hot, tf.transpose(quantizer.embeddings))  # [n*h*w, D]\n",
        "\n",
        "    #reshape back to the expected format [n, h, w, D]\n",
        "    h = w = IMG_SIZE // 4\n",
        "    quantized = tf.reshape(flat_quantized, [n, h, w, LATENT_DIM])\n",
        "    print(f\"Final quantized shape: {quantized.shape}\")\n",
        "\n",
        "    images = decoder(quantized)\n",
        "    return images.numpy()\n",
        "\n",
        "#alternative implementation if the above doesn't work\n",
        "def generate_alt(n=5):\n",
        "    h, w = IMG_SIZE//4, IMG_SIZE//4\n",
        "\n",
        "    \n",
        "    print(f\"Using LATENT_DIM: {LATENT_DIM}\")\n",
        "\n",
        "    random_latents = tf.random.normal((n, h, w, LATENT_DIM))\n",
        "    print(f\"Random latents shape: {random_latents.shape}\")\n",
        "\n",
        "    images = decoder(random_latents)\n",
        "    return images.numpy()\n",
        "\n",
        "# Try the first method\n",
        "# Replace the existing try/except block with this\n",
        "try:\n",
        "    print(\"Generating with improved method...\")\n",
        "    imgs = generate_improved(10, temperature=0.5)\n",
        "except Exception as e:\n",
        "    print(f\"Improved method failed: {e}\")\n",
        "    print(\"Trying alternative method...\")\n",
        "    try:\n",
        "        imgs = generate(10)\n",
        "    except Exception as e:\n",
        "        print(f\"Original method failed: {e}\")\n",
        "        print(\"Falling back to simplest method...\")\n",
        "        imgs = generate_alt(10)\n",
        "\n",
        "# Optional: Apply denoising\n",
        "try:\n",
        "    imgs = denoise_images(imgs, strength=0.5)\n",
        "    print(\"Applied denoising filter\")\n",
        "except ImportError:\n",
        "    print(\"Scipy not available for denoising\")\n",
        "#display the generated images\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(1, len(imgs), figsize=(15,3))\n",
        "for i, im in enumerate(imgs):\n",
        "    # For color images\n",
        "    if im.shape[-1] == 3:\n",
        "        axs[i].imshow(im)\n",
        "    # For grayscale\n",
        "    else:\n",
        "        axs[i].imshow(im.squeeze(), cmap=\"gray\")\n",
        "    axs[i].axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDmZhi33NxdZ"
      },
      "outputs": [],
      "source": [
        "def compute_average_reconstruction_loss(model, dataset):\n",
        "    total_loss = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    for batch in dataset:\n",
        "        recon = model.decoder(model.quantizer(model.encoder(batch)))\n",
        "        loss = tf.reduce_sum(tf.abs(recon - batch))  # L1 loss\n",
        "        total_loss += loss.numpy()\n",
        "        num_samples += tf.size(batch).numpy()\n",
        "\n",
        "    avg_loss = total_loss / num_samples\n",
        "    return avg_loss\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
